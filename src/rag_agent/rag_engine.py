import os
import google.generativeai as genai
import chromadb
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# 1. Ortam DeÄŸiÅŸkenlerini YÃ¼kle (.env dosyasÄ±ndan)
load_dotenv("key.env")

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("âŒ Hata: GOOGLE_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol et.")

# Gemini KonfigÃ¼rasyonu
genai.configure(api_key=GOOGLE_API_KEY)

# --- AYARLAR ---
CHROMA_PATH = os.path.join("data", "chroma_db")
COLLECTION_NAME = "kanunlar_db"
EMBEDDING_MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'

class LegalRAG:
    def __init__(self):
        print("ğŸ¤– RAG Sistemi BaÅŸlatÄ±lÄ±yor...")

        # Embedding Modelini YÃ¼kle (SorgularÄ± vektÃ¶re Ã§evirmek iÃ§in)
        print("   â†³ Embedding modeli yÃ¼kleniyor...")
        self.embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)

        # ChromaDB BaÄŸlantÄ±sÄ±
        print("   â†³ VektÃ¶r veritabanÄ±na baÄŸlanÄ±lÄ±yor...")
        self.chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)
        self.collection = self.chroma_client.get_collection(name=COLLECTION_NAME)

        # Gemini Modeli (Flash modeli hÄ±zlÄ± ve Ã¼cretsiz tier iÃ§in ideal)
        print("   â†³ Gemini 2.5 Flash hazÄ±rlanÄ±yor...")
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    def retrieve_documents(self, query, n_results=3):
        """KullanÄ±cÄ±nÄ±n sorusuna en uygun kanun maddelerini bulur."""
        # Soruyu vektÃ¶re Ã§evir
        query_vector = self.embedding_model.encode(query).tolist()

        # VeritabanÄ±nda ara
        results = self.collection.query(
            query_embeddings=[query_vector],
            n_results=n_results,
            include=["documents", "metadatas"]
        )

        return results

    def generate_answer(self, query):
        """Bulunan belgeleri kullanarak Gemini ile cevap Ã¼retir."""

        # 1. AlakalÄ± Belgeleri Getir (Retrieval)
        search_results = self.retrieve_documents(query)

        docs = search_results['documents'][0]
        metadatas = search_results['metadatas'][0]

        # 2. Context (BaÄŸlam) OluÅŸtur
        context_text = ""
        for i, doc in enumerate(docs):
            source_info = f"{metadatas[i]['source']} - {metadatas[i]['article']}"
            context_text += f"KAYNAK {i+1} ({source_info}):\n{doc}\n\n"

        # 3. System Prompt (Yapay Zeka'ya Rol Verme)
        # BurasÄ± "Prompt Engineering" sanatÄ±nÄ±n konuÅŸturulduÄŸu yerdir.
        system_prompt = f"""
Sen "BilgeKanun AI" adÄ±nda uzman bir TÃ¼rk Hukuku asistanÄ±sÄ±n.
GÃ¶revin: KullanÄ±cÄ±nÄ±n sorusunu, SADECE aÅŸaÄŸÄ±da verilen kanun maddelerine (Context) dayanarak cevaplamaktÄ±r.

KURALLAR:
1. Sadece verilen baÄŸlamdaki bilgiyi kullan. BaÄŸlamda bilgi yoksa "Bu konuda veritabanÄ±mda bilgi bulunmuyor." de.
2. Cevap verirken mutlaka hangi kanun maddesine atÄ±fta bulunduÄŸunu belirt (Ã–rn: "Ä°ÅŸ Kanunu Madde 24'e gÃ¶re...").
3. Hukuki terimleri koru ama vatandaÅŸa anlatÄ±r gibi aÃ§Ä±k ve net ol.
4. Asla kendi hayal gÃ¼cÃ¼nle kanun uydurma.

BAÄLAM (CONTEXT):
{context_text}

KULLANICI SORUSU:
{query}
"""
        # 4. Gemini'ye GÃ¶nder ve CevabÄ± Al
        response = self.model.generate_content(system_prompt)
        return response.text, metadatas

# --- TEST KISMI (DoÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda) ---
if __name__ == "__main__":
    rag = LegalRAG()

    while True:
        soru = input("\nâš–ï¸  Hukuki Sorunuz (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): ")
        if soru.lower() == 'q':
            break

        print("\nâ³ DÃ¼ÅŸÃ¼nÃ¼yor ve araÅŸtÄ±rÄ±yorum...")
        cevap, kaynaklar = rag.generate_answer(soru)

        print("\n" + "="*50)
        print("ğŸ¤– BÄ°LGEKANUN AI CEVABI:")
        print("="*50)
        print(cevap)
        print("\nğŸ“š KULLANILAN KAYNAKLAR:")
        for k in kaynaklar:
            print(f"- {k['source']} {k['article']}")
        print("="*50)